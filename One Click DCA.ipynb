{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b8986a",
   "metadata": {
    "papermill": {
     "duration": 0.005178,
     "end_time": "2024-08-13T17:26:00.143481",
     "exception": false,
     "start_time": "2024-08-13T17:26:00.138303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71236b4e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:00.154742Z",
     "iopub.status.busy": "2024-08-13T17:26:00.154305Z",
     "iopub.status.idle": "2024-08-13T17:26:00.990484Z",
     "shell.execute_reply": "2024-08-13T17:26:00.989373Z"
    },
    "papermill": {
     "duration": 0.845469,
     "end_time": "2024-08-13T17:26:00.993805",
     "exception": false,
     "start_time": "2024-08-13T17:26:00.148336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cmcgainers2/cmc-gain-dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451bfc1",
   "metadata": {
    "papermill": {
     "duration": 0.004796,
     "end_time": "2024-08-13T17:26:01.003826",
     "exception": false,
     "start_time": "2024-08-13T17:26:00.999030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Defining Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3e747a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.015264Z",
     "iopub.status.busy": "2024-08-13T17:26:01.014727Z",
     "iopub.status.idle": "2024-08-13T17:26:01.043371Z",
     "shell.execute_reply": "2024-08-13T17:26:01.042124Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.037126,
     "end_time": "2024-08-13T17:26:01.045893",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.008767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cmc-gain-dataset.csv      int64\n",
      "CMC_Rank                 object\n",
      "Name                     object\n",
      "Symbol                   object\n",
      "Price($)                 object\n",
      "24h%                    float64\n",
      "24h_Vol($)               object\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "#Assumes that your csv file as a single row o'f defined header (starting point, first row)\n",
    "\n",
    "cleanedFilepath = '/kaggle/working/cmc-gain-dataset-Clean.csv'\n",
    "filepath = '/kaggle/input/cmcgainers2/cmc-gain-dataset.csv'\n",
    "csvFile = pd.read_csv(filepath)\n",
    "print(csvFile.dtypes)#prints datatypes for each col\n",
    "print(type(csvFile))#prints <class 'pandas.core.frame.DataFrame'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3983a0",
   "metadata": {
    "papermill": {
     "duration": 0.004678,
     "end_time": "2024-08-13T17:26:01.055422",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.050744",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FillingNull Fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4f90d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.066748Z",
     "iopub.status.busy": "2024-08-13T17:26:01.066365Z",
     "iopub.status.idle": "2024-08-13T17:26:01.072703Z",
     "shell.execute_reply": "2024-08-13T17:26:01.071573Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.014678,
     "end_time": "2024-08-13T17:26:01.074954",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.060276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To fill empty cells\n",
    "def fillNullCells(workingCol):\n",
    "    workingCol = pd.to_numeric(workingCol, errors='coerce')\n",
    "    if pd.isna(workingCol.iloc[0]):#Probably first cell in col is empty\n",
    "        colMedian = workingCol.median()\n",
    "        workingCol.iloc[0] = colMedian#interpolate doesnt fill the first cell id its empty so need to fill manually\n",
    "    workingCol.fillna(workingCol.interpolate(), inplace=True)#Using interpolate as it is best fit for time series data\n",
    "    #print(workingCol)\n",
    "    return workingCol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce6ce4",
   "metadata": {
    "papermill": {
     "duration": 0.004732,
     "end_time": "2024-08-13T17:26:01.084678",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.079946",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TurnAlphabetsToLowercase Fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22806b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.096004Z",
     "iopub.status.busy": "2024-08-13T17:26:01.095629Z",
     "iopub.status.idle": "2024-08-13T17:26:01.102924Z",
     "shell.execute_reply": "2024-08-13T17:26:01.101812Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015674,
     "end_time": "2024-08-13T17:26:01.105232",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.089558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To turn alphabets to lowercase\n",
    "def turnAlphaLower(workingCol):\n",
    "    for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n",
    "        if pd.isna(elmt): #skips an empty cell\n",
    "            continue\n",
    "        try: #To avoid float * isalpha * str * strip errors when there are empty cells in the col\n",
    "            #elmt = re.sub('[^a-zA-Z0-9]+', '', str(elmt))#remove all whitespaces and special characters that negates alphabets or numbers from each elmt, no need for 'str'\n",
    "            elmt = re.sub(r'[^a-zA-Z0-9]+', '', elmt)\n",
    "            try: #To catch errors that will come from values other than numbers\n",
    "                floatelmt = float(elmt)\n",
    "            except: #Then value is str or unknown, i.e mix of chars\n",
    "                if not elmt.isalpha() and  not elmt.isalnum():#If value tossed here is not an alphabet and not alphanumeric\n",
    "                    csvFile.at[idx, col] = np.nan\n",
    "                else:\n",
    "                    csvFile.at[idx, col] = elmt.lower() #return the elmt in lowercase without spaces \n",
    "        except:\n",
    "            continue #skip the empty cell\n",
    "    return workingCol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51fa18e",
   "metadata": {
    "papermill": {
     "duration": 0.004665,
     "end_time": "2024-08-13T17:26:01.114885",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.110220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Mapping Fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4ca115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.126279Z",
     "iopub.status.busy": "2024-08-13T17:26:01.125875Z",
     "iopub.status.idle": "2024-08-13T17:26:01.133798Z",
     "shell.execute_reply": "2024-08-13T17:26:01.132599Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.016366,
     "end_time": "2024-08-13T17:26:01.136109",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.119743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To map each nonnumerical elemt to a num\n",
    "def mapElmtToNum(workingCol):\n",
    "    nonNum = []\n",
    "    for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n",
    "        if pd.isna(elmt): #skips an empty cell\n",
    "            continue\n",
    "        try: #Try to get if its a num\n",
    "            floatelmt = float(elmt)\n",
    "        except: #Then value is str or unknown, i.e mix of chars\n",
    "            nonNum.append(elmt)\n",
    "    nonNum = pd.unique(pd.Series(nonNum))\n",
    "    startNum = pd.to_numeric(workingCol, errors='coerce').max()+1#Trying to get max num in the col, turning all num to float and nonnum to nan\n",
    "    mapped = {val: idx for idx, val in enumerate(nonNum, start=int(startNum))}\n",
    "    workingCol = workingCol.map(lambda elmt: mapped.get(elmt, elmt))\n",
    "    workingCol = pd.to_numeric(workingCol, errors='coerce')\n",
    "    workingCol = fillNullCells(workingCol)\n",
    "    return workingCol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850f3e3",
   "metadata": {
    "papermill": {
     "duration": 0.004823,
     "end_time": "2024-08-13T17:26:01.146062",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.141239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IsCategorical Fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b30af6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.158907Z",
     "iopub.status.busy": "2024-08-13T17:26:01.157829Z",
     "iopub.status.idle": "2024-08-13T17:26:01.164840Z",
     "shell.execute_reply": "2024-08-13T17:26:01.163708Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.015834,
     "end_time": "2024-08-13T17:26:01.167359",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.151525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To determine for categorical col\n",
    "def isCategorical(workingCol):\n",
    "    numValues = sum(workingCol.isna() == False)#Total num of vals in the col\n",
    "    numUniks = workingCol.nunique()#Total num of unique vals\n",
    "    numTwiceUniques = sum(workingCol.value_counts() >= 2)#Total num of vals that reapeat atb least twice\n",
    "    #print(workingCol.value_counts()) # To get a view of the freq of each val\n",
    "\n",
    "    #Using max 60% should be unique threshold\n",
    "    #isCat = (numUniks / numValues) #The ratio of unique vals to total vals\n",
    "    #print(isCat)\n",
    "    #if isCat <= 0.6:\n",
    "        #Turn to category\n",
    "    #else:\n",
    "        #csvFile.drop(workingCol)#Means its not categorical so delete col\n",
    "    \n",
    "    #Using 60% of unique should repeat at least twice threshold\n",
    "    #isCat2 = (0.4 * numUniks)#preferred ratio\n",
    "    #print(isCat2)\n",
    "    #if isCat2 <= numTwiceUniques:\n",
    "        #Turn to categorical\n",
    "        #workingCol = mapElmtToNum(workingCol)\n",
    "        #return workingCol\n",
    "    \n",
    "    #OR\n",
    "    if (numTwiceUniques / numUniks) >= 0.4:\n",
    "        #Turn to categorical\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return None #This col is not cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66cdd57",
   "metadata": {
    "papermill": {
     "duration": 0.004781,
     "end_time": "2024-08-13T17:26:01.177217",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.172436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MapCategorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff1478f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.188810Z",
     "iopub.status.busy": "2024-08-13T17:26:01.188459Z",
     "iopub.status.idle": "2024-08-13T17:26:01.195324Z",
     "shell.execute_reply": "2024-08-13T17:26:01.194249Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.01545,
     "end_time": "2024-08-13T17:26:01.197656",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.182206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To map categorical col, needed this fxn cus I couldn't call this one in another fxn, need to return boolean to do that\n",
    "def mapCategorical(workingCol):\n",
    "    numValues = sum(workingCol.isna() == False)#Total num of vals in the col\n",
    "    numUniks = workingCol.nunique()#Total num of unique vals\n",
    "    numTwiceUniques = sum(workingCol.value_counts() >= 2)#Total num of vals that reapeat atb least twice\n",
    "    #print(workingCol.value_counts()) # To get a view of the freq of each val\n",
    "\n",
    "    #Using max 60% should be unique threshold\n",
    "    #isCat = (numUniks / numValues) #The ratio of unique vals to total vals\n",
    "    #print(isCat)\n",
    "    #if isCat <= 0.6:\n",
    "        #Turn to category\n",
    "    #else:\n",
    "        #csvFile.drop(workingCol)#Means its not categorical so delete col\n",
    "    \n",
    "    #Using 60% of unique should repeat at least twice threshold\n",
    "    #isCat2 = (0.4 * numUniks)#preferred ratio\n",
    "    #print(isCat2)\n",
    "    #if isCat2 <= numTwiceUniques:\n",
    "        #Turn to categorical\n",
    "        #workingCol = mapElmtToNum(workingCol)\n",
    "        #return workingCol\n",
    "    \n",
    "    #OR\n",
    "    if (numTwiceUniques / numUniks) >= 0.4:\n",
    "        #Turn to categorical\n",
    "        workingCol = mapElmtToNum(workingCol)\n",
    "        return workingCol\n",
    "    \n",
    "    else:\n",
    "        return None #This col is not cleaned\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe501a66",
   "metadata": {
    "papermill": {
     "duration": 0.004861,
     "end_time": "2024-08-13T17:26:01.207615",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.202754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CleaningMixed Fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd2f048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.219653Z",
     "iopub.status.busy": "2024-08-13T17:26:01.218970Z",
     "iopub.status.idle": "2024-08-13T17:26:01.226079Z",
     "shell.execute_reply": "2024-08-13T17:26:01.224893Z"
    },
    "papermill": {
     "duration": 0.015663,
     "end_time": "2024-08-13T17:26:01.228300",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.212637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To clean a num col mixed with other chars\n",
    "def cleanObjNumericalCol(workingCol):\n",
    "    numUniks = workingCol.nunique()\n",
    "    numValues = sum(workingCol.isna() == False)\n",
    "    if isCategorical(workingCol):\n",
    "        return True\n",
    "    elif numUniks >= 0.6 * numValues:#To check if the col is not categorical i.e. not repeated values\n",
    "        for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n",
    "            if pd.isna(elmt): #skips an empty cell\n",
    "                continue\n",
    "            elmt = re.sub(r'[^a-zA-Z0-9.]+', '', elmt)\n",
    "        #    try:\n",
    "        #        floatelmt = float(elmt)\n",
    "        #    except:\n",
    "        #        csvFile.at[idx, col] = np.nan\n",
    "        workingCol = pd.to_numeric(workingCol, errors='coerce')\n",
    "        workingCol = fillNullCells(workingCol)\n",
    "        return workingCol\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74a2da",
   "metadata": {
    "papermill": {
     "duration": 0.004738,
     "end_time": "2024-08-13T17:26:01.238131",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.233393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Count Values Fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78fe0525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.249768Z",
     "iopub.status.busy": "2024-08-13T17:26:01.249411Z",
     "iopub.status.idle": "2024-08-13T17:26:01.257061Z",
     "shell.execute_reply": "2024-08-13T17:26:01.255987Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.016032,
     "end_time": "2024-08-13T17:26:01.259209",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.243177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#To count each elmt in each col\n",
    "def countObjsCol(workingCol):\n",
    "    strCount = 0\n",
    "    alphanumericCount = 0\n",
    "    numCount = 0\n",
    "    unknownCount = 0\n",
    "    #for elmt in csvFile[col]:#itrs over each elmt in a single col\n",
    "    \n",
    "    for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n",
    "        if pd.isna(elmt): #skips an empty cell\n",
    "            continue\n",
    "        try: #To avoid float * isalpha * str * strip errors when there are empty cells in the col\n",
    "            elmt = re.sub(r'[,\\s]+', '', elmt)#remove all whitespaces and commas ONLY from each elmt (need to know unknowns)\n",
    "            if elmt.isalpha():#Checks if each elmt is an alphabet\n",
    "                strCount += 1\n",
    "                #print(elmt)#prints the alphabetical elmt\n",
    "            \n",
    "            else:\n",
    "                try: #To catch errors that will come from values other than numbers\n",
    "                    floatnum = float(elmt)\n",
    "                    numCount += 1\n",
    "                except:\n",
    "                    if elmt.isalnum():#For alphanum chars\n",
    "                        alphanumericCount += 1 \n",
    "                    else:\n",
    "                        unknownCount += 1 #Then value is unknown, i.e mix of chars \n",
    "                    continue #skip the value\n",
    "                \n",
    "        except:\n",
    "            continue #skip the empty cel\n",
    "    return strCount, alphanumericCount, numCount, unknownCount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0159d",
   "metadata": {
    "papermill": {
     "duration": 0.005539,
     "end_time": "2024-08-13T17:26:01.269875",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.264336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b83c42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:26:01.281557Z",
     "iopub.status.busy": "2024-08-13T17:26:01.281153Z",
     "iopub.status.idle": "2024-08-13T17:26:01.345815Z",
     "shell.execute_reply": "2024-08-13T17:26:01.344641Z"
    },
    "papermill": {
     "duration": 0.074959,
     "end_time": "2024-08-13T17:26:01.349796",
     "exception": false,
     "start_time": "2024-08-13T17:26:01.274837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMC_Rank\n",
      "String:  36\n",
      "Alphanumeric:  0\n",
      "Nums:  19\n",
      "Unknown:  3\n",
      "Name\n",
      "String:  57\n",
      "Alphanumeric:  0\n",
      "Nums:  0\n",
      "Unknown:  2\n",
      "Symbol\n",
      "String:  21\n",
      "Alphanumeric:  0\n",
      "Nums:  38\n",
      "Unknown:  0\n",
      "0      FIL\n",
      "1      APT\n",
      "2      ADA\n",
      "3       36\n",
      "4       52\n",
      "5       62\n",
      "6       36\n",
      "7       36\n",
      "8       52\n",
      "9       62\n",
      "10      36\n",
      "11      62\n",
      "12      36\n",
      "13     LTC\n",
      "14     LTC\n",
      "15     LTC\n",
      "16     FIL\n",
      "17     APT\n",
      "18     ADA\n",
      "19      36\n",
      "20      52\n",
      "21      62\n",
      "22      36\n",
      "23      36\n",
      "24      52\n",
      "25      62\n",
      "26      36\n",
      "27      62\n",
      "28      52\n",
      "29      62\n",
      "30      36\n",
      "31      62\n",
      "32      36\n",
      "33      18\n",
      "34      28\n",
      "35      21\n",
      "36     LTC\n",
      "37     LTC\n",
      "38     LTC\n",
      "39     FIL\n",
      "40     APT\n",
      "41     ADA\n",
      "42      36\n",
      "43      52\n",
      "44      62\n",
      "45      36\n",
      "46      36\n",
      "47      52\n",
      "48      62\n",
      "49      36\n",
      "50      62\n",
      "51      62\n",
      "52      36\n",
      "53    SAND\n",
      "54     CFX\n",
      "55     MKR\n",
      "56    XAUt\n",
      "57     AXS\n",
      "58     KCS\n",
      "Name: Symbol, dtype: object\n",
      "Price($)\n",
      "String:  13\n",
      "Alphanumeric:  0\n",
      "Nums:  45\n",
      "Unknown:  1\n",
      "0        1.680000\n",
      "1        0.170000\n",
      "2        1.700000\n",
      "3        1.020000\n",
      "4        1.640000\n",
      "5       92.650000\n",
      "6        0.711200\n",
      "7       23.660000\n",
      "8        0.024840\n",
      "9        7.600000\n",
      "10       1.980000\n",
      "11       4.040000\n",
      "12       6.290000\n",
      "13       0.396300\n",
      "14       0.026630\n",
      "15       0.134400\n",
      "16       0.998900\n",
      "17       1.340000\n",
      "18       0.000009\n",
      "19       4.840000\n",
      "20     158.300000\n",
      "21      67.930000\n",
      "22       0.000002\n",
      "23       6.810000\n",
      "24       0.142600\n",
      "25       0.478600\n",
      "26       0.721000\n",
      "27       0.532400\n",
      "28       1.143667\n",
      "29       1.754933\n",
      "30       2.366200\n",
      "31       2.977467\n",
      "32       3.588733\n",
      "33       4.200000\n",
      "34      23.920000\n",
      "35      94.200000\n",
      "36       0.000002\n",
      "37       0.766500\n",
      "38       1.490000\n",
      "39       7.530000\n",
      "40       0.027090\n",
      "41     350.430000\n",
      "42       1.100000\n",
      "43       0.324000\n",
      "44       0.475778\n",
      "45       0.627556\n",
      "46       0.779333\n",
      "47       0.931111\n",
      "48       1.082889\n",
      "49       1.234667\n",
      "50       1.386444\n",
      "51       1.538222\n",
      "52       1.690000\n",
      "53       0.305700\n",
      "54       0.143300\n",
      "55    2347.440000\n",
      "56    1176.435000\n",
      "57       5.430000\n",
      "58       9.070000\n",
      "Name: Price($), dtype: float64\n",
      "24h_Vol($)\n",
      "String:  0\n",
      "Alphanumeric:  0\n",
      "Nums:  58\n",
      "Unknown:  1\n",
      "0     1.681903e+08\n",
      "1     1.377070e+08\n",
      "2     1.698009e+08\n",
      "3     1.310652e+08\n",
      "4     1.147164e+08\n",
      "5     9.125701e+07\n",
      "6     1.065566e+08\n",
      "7     5.238912e+07\n",
      "8     9.396497e+07\n",
      "9     5.004281e+07\n",
      "10    1.074268e+07\n",
      "11    8.753568e+07\n",
      "12    7.116365e+07\n",
      "13    2.440305e+08\n",
      "14    3.104213e+07\n",
      "15    3.331033e+08\n",
      "16    2.340181e+07\n",
      "17    1.497144e+07\n",
      "18    5.463680e+08\n",
      "19    2.063009e+08\n",
      "20    6.440599e+07\n",
      "21    2.181673e+08\n",
      "22    3.028238e+07\n",
      "23    1.244104e+08\n",
      "24    2.290218e+07\n",
      "25    7.489047e+07\n",
      "26    1.670282e+08\n",
      "27    6.085400e+07\n",
      "28    3.181942e+07\n",
      "29    2.263332e+07\n",
      "30    1.750163e+08\n",
      "31    2.738914e+08\n",
      "32    1.676243e+08\n",
      "33    1.461961e+08\n",
      "34    1.037313e+08\n",
      "35    1.146794e+08\n",
      "36    3.675928e+07\n",
      "37    1.392865e+08\n",
      "38    1.456849e+07\n",
      "39    5.883386e+07\n",
      "40    3.991386e+07\n",
      "41    2.741593e+08\n",
      "42    4.968526e+06\n",
      "43    3.435371e+07\n",
      "44    2.987282e+08\n",
      "45    2.401250e+07\n",
      "46    2.430372e+08\n",
      "47    1.065670e+09\n",
      "48    1.632617e+08\n",
      "49    4.424682e+07\n",
      "50    3.649999e+08\n",
      "51    1.778988e+07\n",
      "52    1.727997e+08\n",
      "53    4.850644e+07\n",
      "54    2.604304e+07\n",
      "55    7.461790e+07\n",
      "56    1.265881e+07\n",
      "57    2.484609e+07\n",
      "58    2.484609e+07\n",
      "Name: 24h_Vol($), dtype: float64\n",
      "cmc-gain-dataset.csv      int64\n",
      "CMC_Rank                float64\n",
      "Symbol                    int64\n",
      "Price($)                float64\n",
      "24h%                    float64\n",
      "24h_Vol($)              float64\n",
      "dtype: object\n",
      "Clean Data Exported Successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Main Operation\n",
    "for col in csvFile.columns:#itrs over all cols at once, but a single col with index def\n",
    "    #pass\n",
    "    #print(csvFile[col]) #Prints the current col\n",
    "    workingCol = csvFile[col]\n",
    "\n",
    "    if csvFile[col].dtype == int: #Its perfect so skip\n",
    "        continue\n",
    "\n",
    "    elif csvFile[col].dtype == float: #Might need fixing\n",
    "        csvFile[col] = fillNullCells(csvFile[col])\n",
    "        #print(csvFile[col])\n",
    "        \n",
    "\n",
    "    elif workingCol.dtype == object: #Checks for each cols first\n",
    "        strCount, alphanumericCount, numCount, unknownCount = countObjsCol(workingCol)\n",
    "        values = strCount + alphanumericCount + numCount\n",
    "        \n",
    "        print(col)\n",
    "        print('String: ', strCount)\n",
    "        print('Alphanumeric: ', alphanumericCount)\n",
    "        print('Nums: ', numCount)\n",
    "        print('Unknown: ', unknownCount)\n",
    "        \n",
    "        if numCount >= (0.6 * values):#Incase a numerical col is mixed with few alphabets\n",
    "            if cleanObjNumericalCol(csvFile[col]) is None:\n",
    "                csvFile.drop(col, axis=1, inplace=True)\n",
    "                \n",
    "            elif cleanObjNumericalCol(csvFile[col]) is True:#It's a categorical col with more numbers \n",
    "                print(csvFile[col])\n",
    "                csvFile[col] = turnAlphaLower(csvFile[col])\n",
    "                csvFile[col] = mapCategorical(csvFile[col])\n",
    "                \n",
    "            else:\n",
    "                csvFile[col] = cleanObjNumericalCol(csvFile[col])#Num col with some empty cells\n",
    "                print(csvFile[col])\n",
    "\n",
    "        #This works well for cols with more alpha chars than the others\n",
    "        elif (strCount + alphanumericCount + numCount) >= (0.8 * sum(csvFile[col].isna() == False)): #This ratio means cols is likely mixed up with invalid data\n",
    "            #print(csvFile[col])\n",
    "            #To determine for Categorical col and then map\n",
    "            if isCategorical(csvFile[col]) is True:\n",
    "                csvFile[col] = turnAlphaLower(csvFile[col])      \n",
    "                csvFile[col] = mapCategorical(csvFile[col])\n",
    "                #print(csvFile[col])\n",
    "            else:\n",
    "                csvFile.drop(col, axis=1, inplace=True)#Means its not categorical so delete col\n",
    "                \n",
    "        else:\n",
    "            #print(workingCol)\n",
    "            csvFile.drop(col, axis=1, inplace=True)#Means its not categorical so delete col\n",
    "            \n",
    "    else:\n",
    "        csvFile.drop(col, axis=1, inplace=True)#Del any other col\n",
    "\n",
    "print(csvFile.dtypes)\n",
    "\n",
    "csvFile.to_csv(cleanedFilepath, index=False)\n",
    "print('Clean Data Exported Successfully')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5539338,
     "sourceId": 9167364,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.422996,
   "end_time": "2024-08-13T17:26:01.776566",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-13T17:25:57.353570",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
