{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9161430,"sourceType":"datasetVersion","datasetId":5374348},{"sourceId":9165945,"sourceType":"datasetVersion","datasetId":5538315},{"sourceId":9166003,"sourceType":"datasetVersion","datasetId":5538352}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-13T12:48:24.835836Z","iopub.execute_input":"2024-08-13T12:48:24.836328Z","iopub.status.idle":"2024-08-13T12:48:24.846830Z","shell.execute_reply.started":"2024-08-13T12:48:24.836290Z","shell.execute_reply":"2024-08-13T12:48:24.845643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assumes that your csv file as a single row o'f defined header (starting point, first row)\n\ncleanedFilepath = '/kaggle/working/cmc-gain-dataset-Clean.csv'\nfilepath = '/kaggle/input/cmcdata2/cmc-gain-dataset.csv'\ncsvFile = pd.read_csv(filepath)\nprint(csvFile.dtypes)#prints datatypes for each col\nprint(type(csvFile))#prints <class 'pandas.core.frame.DataFrame'>\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To fill empty cells\ndef fillNullCells(workingCol):\n    workingCol = pd.to_numeric(workingCol, errors='coerce')\n    if pd.isna(workingCol.iloc[0]):#Probably first cell in col is empty\n        colMedian = workingCol.median()\n        workingCol.iloc[0] = colMedian#interpolate doesnt fill the first cell id its empty so need to fill manually\n    workingCol.fillna(workingCol.interpolate(), inplace=True)#Using interpolate as it is best fit for time series data\n    #print(workingCol)\n    return workingCol\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To clean a num col mixed with other chars\ndef cleanObjNumericalCol(workingCol):\n    numUniks = workingCol.nunique()\n    numValues = sum(workingCol.isna() == False)\n    if numUniks >= 0.6 * numValues:#To check if the col is not categorical i.e. not repeated values\n        for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n            if pd.isna(elmt): #skips an empty cell\n                continue\n            elmt = re.sub(r'[^a-zA-Z0-9.]+', '', elmt)\n        #    try:\n        #        floatelmt = float(elmt)\n        #    except:\n        #        csvFile.at[idx, col] = np.nan\n        workingCol = pd.to_numeric(workingCol, errors='coerce')\n        workingCol = fillNullCells(workingCol)\n        return workingCol\n    else:\n        return None\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To count each elmt in each col\ndef countObjsCol(workingCol):\n    strCount = 0\n    alphanumericCount = 0\n    numCount = 0\n    unknownCount = 0\n    #for elmt in csvFile[col]:#itrs over each elmt in a single col\n    \n    for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n        if pd.isna(elmt): #skips an empty cell\n            continue\n        try: #To avoid float * isalpha * str * strip errors when there are empty cells in the col\n            elmt = re.sub(r'[,\\s]+', '', elmt)#remove all whitespaces and commas ONLY from each elmt (need to know unknowns)\n            if elmt.isalpha():#Checks if each elmt is an alphabet\n                strCount += 1\n                #print(elmt)#prints the alphabetical elmt\n            \n            else:\n                try: #To catch errors that will come from values other than numbers\n                    floatnum = float(elmt)\n                    numCount += 1\n                except:\n                    if elmt.isalnum():#For alphanum chars\n                        alphanumericCount += 1 \n                    else:\n                        unknownCount += 1 #Then value is unknown, i.e mix of chars \n                    continue #skip the value\n                \n        except:\n            continue #skip the empty cel\n    return strCount, alphanumericCount, numCount, unknownCount\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To turn alphabets to lowercase\ndef turnAlphaLower(workingCol):\n    for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n        if pd.isna(elmt): #skips an empty cell\n            continue\n        try: #To avoid float * isalpha * str * strip errors when there are empty cells in the col\n            #elmt = re.sub('[^a-zA-Z0-9]+', '', str(elmt))#remove all whitespaces and special characters that negates alphabets or numbers from each elmt, no need for 'str'\n            elmt = re.sub(r'[^a-zA-Z0-9]+', '', elmt)\n            try: #To catch errors that will come from values other than numbers\n                floatelmt = float(elmt)\n            except: #Then value is str or unknown, i.e mix of chars\n                if not elmt.isalpha() and  not elmt.isalnum():#If value tossed here is not an alphabet and not alphanumeric\n                    csvFile.at[idx, col] = np.nan\n                else:\n                    csvFile.at[idx, col] = elmt.lower() #return the elmt in lowercase without spaces \n        except:\n            continue #skip the empty cell\n    return workingCol\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To map each nonnumerical elemt to a num\ndef mapElmtToNum(workingCol):\n    nonNum = []\n    for idx, elmt in enumerate(workingCol):#itrs over each elmt in a single col \n        if pd.isna(elmt): #skips an empty cell\n            continue\n        try: #Try to get if its a num\n            floatelmt = float(elmt)\n        except: #Then value is str or unknown, i.e mix of chars\n            nonNum.append(elmt)\n    nonNum = pd.unique(pd.Series(nonNum))\n    startNum = pd.to_numeric(workingCol, errors='coerce').max()+1#Trying to get max num in the col, turning all num to float and nonnum to nan\n    mapped = {val: idx for idx, val in enumerate(nonNum, start=int(startNum))}\n    workingCol = workingCol.map(lambda elmt: mapped.get(elmt, elmt))\n    workingCol = pd.to_numeric(workingCol, errors='coerce')\n    workingCol = fillNullCells(workingCol)\n    return workingCol\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To determine for categorical col\ndef isCategorical(workingCol):\n    numValues = sum(workingCol.isna() == False)#Total num of vals in the col\n    numUniks = workingCol.nunique()#Total num of unique vals\n    numTwiceUniques = sum(workingCol.value_counts() >= 2)#Total num of vals that reapeat atb least twice\n    #print(workingCol.value_counts()) # To get a view of the freq of each val\n\n    #Using max 60% should be unique threshold\n    #isCat = (numUniks / numValues) #The ratio of unique vals to total vals\n    #print(isCat)\n    #if isCat <= 0.6:\n        #Turn to category\n    #else:\n        #csvFile.drop(workingCol)#Means its not categorical so delete col\n    #Using 60% of unique should repeat at least twice threshold\n    isCat2 = (0.6 * numUniks)#preferred ratio\n    #print(isCat2)\n    if isCat2 <= numTwiceUniques:\n        #Turn to categorical\n        workingCol = mapElmtToNum(workingCol)\n        return workingCol\n    \n    else:\n        return None #This col is not cleaned\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Main Operation\nfor col in csvFile.columns:#itrs over all cols at once, but a single col with index def\n    #pass\n    #print(csvFile[col]) #Prints the current col\n    workingCol = csvFile[col]\n\n    if csvFile[col].dtype == int: #Its perfect\n        continue\n\n    elif csvFile[col].dtype == float: #Might need fixing\n        csvFile[col] = fillNullCells(csvFile[col])\n        #print(csvFile[col])\n        \n\n    elif workingCol.dtype == object: #Checks for each cols first\n        strCount, alphanumericCount, numCount, unknownCount = countObjsCol(workingCol)\n        values = strCount + alphanumericCount + numCount\n        \n        #print(col)\n        #print('String: ', strCount)\n        #print('Alphanumeric: ', alphanumericCount)\n        #print('Nums: ', numCount)\n        #print('Unknown: ', unknownCount)\n        \n        if workingCol is (numCount >= 0.6 * values):# and isCategorical(workingCol):#Incase a numerical col is mixed with few alphabets\n            if cleanObjNumericalCol(csvFile[col]) is None:\n                csvFile.drop(col, axis=1, inplace=True)\n            else:\n                csvFile[col] = turnAlphaLower(csvFile[col])\n                csvFile[col] = cleanObjNumericalCol(csvFile[col])#Num col with some empty cells\n                csvFile[col] = isCategorical(csvFile[col])\n                #print(csvFile[col])\n\n        #This works well for cols with more alpha chars than the others\n        elif (strCount + alphanumericCount + numCount) >= (0.8 * sum(workingCol.isna() == False)): #This ratio means cols is likely mixed up with invalid data\n            #To determine for Categorical col and then map\n            if isCategorical(csvFile[col]) is None:\n                csvFile.drop(col, axis=1, inplace=True)#Means its not categorical so delete col\n            else:\n                csvFile[col] = turnAlphaLower(csvFile[col])      \n                csvFile[col] = isCategorical(csvFile[col])\n                #print(csvFile[col])\n\n\n        else:\n            #print(workingCol)\n            csvFile.drop(col, axis=1, inplace=True)#Means its not categorical so delete col\n            \n    else:\n        csvFile.drop(col, axis=1, inplace=True)#Del any other col\n\nprint(csvFile.dtypes)\n\ncsvFile.to_csv(cleanedFilepath, index=False)\nprint('Clean Data Exported Successfully')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-13T12:54:17.752826Z","iopub.execute_input":"2024-08-13T12:54:17.753276Z","iopub.status.idle":"2024-08-13T12:54:17.805940Z","shell.execute_reply.started":"2024-08-13T12:54:17.753243Z","shell.execute_reply":"2024-08-13T12:54:17.804640Z"},"trusted":true},"execution_count":null,"outputs":[]}]}